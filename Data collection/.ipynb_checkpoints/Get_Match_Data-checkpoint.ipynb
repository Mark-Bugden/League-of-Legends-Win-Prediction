{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7000f112-5022-4cb4-8f87-9a3e87897d1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting match data from the RIOT games API\n",
    "This notebook goes through the process of aggregating match data from the RIOT games API. Due to rate limiting and the convoluted method of obtaining match data, the process can take quite a while. Where possible, I have saved the intermediate results so that long steps do not need to be repeated. \n",
    "\n",
    "## Here is the workflow for obtaining the data:\n",
    "\n",
    "- [X] Step 1. Obtain summoner IDs by looking up the summoner data from the first 100 pages of each tier and division \n",
    "(save summoner_ids to 'summoner_id_file')\n",
    "\n",
    "- [X] Step 2. Use those summoner IDs to obtain the corresponding PUUIDs\n",
    "(save puuids in a pickle file 'PUUIDs' )\n",
    "\n",
    "- [X] Step 3. Use the PUUIDs to query the match history of those summoners, obtaining a list of match IDs\n",
    "(save match IDs in a pickle file 'match_IDs' )\n",
    "\n",
    "- [ ] Step 4. Use the match IDs to get the match data\n",
    "(save match data in a pickle file 'match_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6bf66e-3062-4b60-8b48-481a6625e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Mark Bugden\n",
    "August 2022\n",
    "\n",
    "Part of a ML project in predicting win rates for League of Legends games based on team composition.\n",
    "Current update available on GitHub: https://github.com/Mark-Bugden\n",
    "\"\"\"\n",
    "\n",
    "# Import anything necessary\n",
    "import requests\n",
    "import pandas as pd\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "\n",
    "# This gives us a progress bar for longer computations. \n",
    "from tqdm.notebook import tqdm\n",
    "# To use it, just wrap any iterable with tqdm(iterable).\n",
    "# Eg: \n",
    "# for i in tqdm(range(100)):\n",
    "#     ....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We need to pick a region. \n",
    "region_list = ['BR1', 'EUN1', 'EUW1', 'JP1', 'KR', 'LA1', 'LA2', 'NA1', 'OC1', 'RU', 'TR1']\n",
    "region = 'EUN1'\n",
    "\n",
    "\n",
    "# Here are the tiers and divisions\n",
    "tier_list = ['DIAMOND', 'PLATINUM', 'GOLD', 'SILVER', 'BRONZE', 'IRON']\n",
    "division_list = ['I', 'II', 'III', 'IV']\n",
    "\n",
    "\n",
    "\n",
    "# Load the data for the champions\n",
    "champion_url = 'http://ddragon.leagueoflegends.com/cdn/12.14.1/data/en_US/champion.json'\n",
    "r = requests.get(champion_url)\n",
    "json_data = r.json()\n",
    "champion_data = json_data['data']\n",
    "\n",
    "#champions = list(champion_data.keys())\n",
    "#champion_data['Zyra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66d108-b745-4581-a53f-74154d1f65f6",
   "metadata": {},
   "source": [
    "### Note: \n",
    "The API rates are meant to be 20/1s and 100/120s, but I have found that I get errors when I set the ratelimit to exactly that. I have found that I don't get any errors when I set it at half the rate, which works for now, but doubles the time required to get the data. I should try it again at slightly over half the rate, to see if I get an error. If I do, then I am probably accidentally accessing the API twice per call instead of once.\n",
    "\n",
    "### Update\n",
    "Setting it at 5/7s seems to be a good compromise. \n",
    "\n",
    "### Update\n",
    "My new API rate limit is 50/10, so to be safe I will set it at 8/2 (which is 40/10).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b07449-eca4-4c37-a66e-6d388592ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful functions\n",
    "\n",
    "\n",
    "def unique(l):\n",
    "  \n",
    "    # insert the list to the set\n",
    "    list_set = set(l)\n",
    "    # convert the set to the list\n",
    "    unique_list = (list(list_set))\n",
    "    return unique_list\n",
    "\n",
    "def flatten(l):\n",
    "    ''' Flattens a list\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        l:list\n",
    "            A list to be flattened\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            The flattened list\n",
    "    \n",
    "    '''\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "def chunks(lst, n):\n",
    "    ''' Splits a list into n equal pieces\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        l:list\n",
    "            A list to be split into chunks\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            The list\n",
    "    '''\n",
    "    n = max(1, n)\n",
    "    k, m = divmod(len(lst), n)\n",
    "    return (lst[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
    "\n",
    "\n",
    "# We will need an API key to access the Riot games API. I have one of these, but I don't want it to be publically available on my GitHub, so I am storing it locally in a text file. \n",
    "\n",
    "def getAPI_key():\n",
    "    ''' Accesses my locally stored API key so that I don't have to include it publically on GitHub\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        string:\n",
    "            My API key for RIOT games\n",
    "\n",
    "    '''\n",
    "    f = open(\"api_key.txt\", \"r\")\n",
    "    return f.read()\n",
    "\n",
    "\n",
    "\n",
    "# Our API calls are rate limited to 100 every 2 minutes, or 20 every second. So we will use the ratelimit package to limit how many times we call the API. \n",
    "# If the rate limit is reached, the program will sleep until it can try again. We will set the rate to 5 calls per 7s. This will be slower for short queries, but won't give us errors long ones.\n",
    "# Note that it should be 5/6s, but for some reason that gave me Error:429. Trying 7s just to be a bit safer.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(8, 2)\n",
    "def callAPI(url):\n",
    "    ''' Send and retrieve API requests, rate limited to the RIOT games API rate limit. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        url: string\n",
    "            The URL of the request you are making. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list of dictionaries encoding the data accessed. \n",
    "    '''\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        raise Exception('API response: {}'.format(r.status_code))\n",
    "        \n",
    "    return r.json()\n",
    "\n",
    "\n",
    "# If I am getting a 401 error, I probably just need to refresh my API key from the developer website\n",
    "# If I am getting a 404 error, there is a problem with that particular entry. \n",
    "\n",
    "\n",
    "\n",
    "def get_summoner_ids(page=1):\n",
    "    '''\n",
    "    Aggregates a list of summoner ids from the first page of all the low-ranking tiers and divisions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        page: int\n",
    "            Which page is queried for the summoner info\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list of summoner ids\n",
    "    \n",
    "    '''\n",
    "    summoners = []\n",
    "\n",
    "    # For all leagues from Iron to Diamond, and for all tiers from I to IV, send a request to get the first page of the summoners for that league and tier.\n",
    "    for tier in tqdm(tier_list):\n",
    "        for division in division_list:\n",
    "\n",
    "            url = 'https://' + region + '.api.riotgames.com/lol/league/v4/entries/RANKED_SOLO_5x5/' + tier + '/' + division + '?page=' + str(page) + '&api_key='\n",
    "\n",
    "            # Here json_data is a list. Each item in the list corresponds to one summoner, and is a dict whose key/value pairs contain information about that summoner.\n",
    "            json_data = callAPI(url + getAPI_key())\n",
    "            \n",
    "\n",
    "            for item in json_data:\n",
    "                summoners.append(item)\n",
    "\n",
    "    summoners_df = pd.DataFrame(summoners)\n",
    "\n",
    "    return summoners_df['summonerId'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_puuids(ids):\n",
    "    ''' Takes a list of summoner ids and queries the RIOT API for their puuids\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        ids: list\n",
    "            A list of summoner ids\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list of the corresponding puuids\n",
    "    '''\n",
    "    \n",
    "    summoner_info = []\n",
    "\n",
    "    for summoner in tqdm(ids):\n",
    "        url = 'https://' + region + '.api.riotgames.com/lol/summoner/v4/summoners/' + summoner + '?api_key='\n",
    "        try:\n",
    "            json_data = callAPI(url + getAPI_key())\n",
    "            summoner_info.append(json_data)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    df_summ = pd.DataFrame(summoner_info)\n",
    "    \n",
    "    return df_summ['puuid'].tolist(), df_summ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_match_ids(puuids, n = 100):\n",
    "    ''' Takes a list of puuids and returns the match IDs for the previous n matches. Any duplicate match IDs are removed. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        puuids: list\n",
    "            A list of puuids to query\n",
    "        n: int \n",
    "            The number of matches to get per puuid\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list of match ids\n",
    "    '''\n",
    "    \n",
    "    match_id = []\n",
    "    \n",
    "    for puuid in tqdm(puuids):\n",
    "        url = 'https://europe.api.riotgames.com/lol/match/v5/matches/by-puuid/' + puuid + '/ids?start=0&count=100&api_key='\n",
    "        try:\n",
    "            json_data = callAPI(url + getAPI_key())\n",
    "            match_id.append(json_data)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return list(set(flatten(match_id)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_match_data(batch):\n",
    "    ''' Accesses the match data for a given batch of match ids and returns the data as a list. Skips an entry if a 404 error is returned\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        batch: list\n",
    "            A list of match ids \n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list containing the match data for each of the match ids in batch\n",
    "            \n",
    "    '''\n",
    "    data_list = []\n",
    "    \n",
    "    for match in tqdm(batch):\n",
    "        url = 'https://europe.api.riotgames.com/lol/match/v5/matches/'+ match + '?api_key='\n",
    "        try:\n",
    "            json_data = callAPI(url + getAPI_key())\n",
    "            data_list.append(json_data)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef373945-b3dc-41b9-80c7-1459cd4afc5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting the Summoner IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d49b3d-84c2-4297-8b16-b5e0489b81da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the summoner ids is as easy as calling the get_summoner_list function \n",
    "# We will get the first, say 100 pages of each division\n",
    "#summoner_ids = []\n",
    "#for page in range(1,101):\n",
    "#    print(page)\n",
    "#    summoner_ids = summoner_ids + get_summoner_ids(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59cd562b-9ad4-46eb-8733-004487499c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we don't have any duplicates\n",
    "#summoner_ids = unique(summoner_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217b79d2-d783-4cfd-959e-da9c28eb5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save them to a file because it took so long to get\n",
    "#with open(\"Step 1 summoner ids/summoner_id_file\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_ids, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b66962-660b-4069-bcf2-138f8c1ec906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the summoner ids\n",
    "with open(\"Step 1 summoner ids/summoner_id_file\", \"rb\") as fp:   # Unpickling\n",
    "    summoner_ids = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54c1a76-88df-4d40-8395-d8aef2714220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summoner_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eccfdb66-c9ee-4d1a-b18c-5c4ba76a2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is such a large number, the next step is going to take a long time. 417256/4 ~ 104300s ~28 hours . We will need to split it up and do it in batches. \n",
    "Numsplits = 8 \n",
    "spl = math.floor(len(summoner_ids)/Numsplits)\n",
    "\n",
    "summoner_id_batches = {}\n",
    "for i in range(0, Numsplits):\n",
    "    summoner_id_batches[f\"batch{i}\"] = summoner_ids[i*spl:(i+1)*spl]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d929c32f-f225-4362-86de-92bd907ed7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['batch0', 'batch1', 'batch2', 'batch3', 'batch4', 'batch5', 'batch6', 'batch7'])\n",
      "lenght of batch0:  52157\n"
     ]
    }
   ],
   "source": [
    "print(summoner_id_batches.keys())\n",
    "print('lenght of batch0: ', len(summoner_id_batches['batch0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153cf18-ceb6-4b8d-b3b3-3e8bd2cb29b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae852ee-ef1c-4606-ac1e-07288fccff69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2e867-68d5-49dd-82ef-c415fd6042e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "502b810d-174b-4cfa-bd61-057efb525ba6",
   "metadata": {},
   "source": [
    "# Getting the PUUIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d61d035-3742-4b3f-a4ce-0b33e0c573b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_puuids takes approximately 3.6 hours on each summoner_id_batches['batchX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78fa1da0-0e2a-4cdd-9d65-399881daea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summoner_puuids, summoner_data = get_puuids(summoner_id_batches['batch0'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 2 puuids/puuid_file_batch0\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_puuids, fp)\n",
    "\n",
    "#with open(\"summoner data/summoner_data_file_batch0\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bfff48e-ff59-474e-94f4-f72ea7115af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summoner_puuids, summoner_data = get_puuids(summoner_id_batches['batch1'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 2 puuids/puuid_file_batch1\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_puuids, fp)\n",
    "\n",
    "#with open(\"summoner data/summoner_data_file_batch1\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a13666d-8be1-4224-a500-d2ad06c64b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summoner_puuids, summoner_data = get_puuids(summoner_id_batches['batch2'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 2 puuids/puuid_file_batch2\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_puuids, fp)\n",
    "\n",
    "#with open(\"summoner data/summoner_data_file_batch2\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c42c54-b29f-4f6e-9c46-c447a5528576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summoner_puuids, summoner_data = get_puuids(summoner_id_batches['batch3'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 2 puuids/puuid_file_batch3\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_puuids, fp)\n",
    "\n",
    "#with open(\"summoner data/summoner_data_file_batch3\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_data, fp)\n",
    "    \n",
    "    \n",
    "#summoner_puuids, summoner_data = get_puuids(summoner_id_batches['batch4'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 2 puuids/puuid_file_batch4\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_puuids, fp)\n",
    "\n",
    "#with open(\"summoner data/summoner_data_file_batch4\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_data, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f555f26-9fdc-4e1d-96aa-8cb8f1604d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summoner_puuids, summoner_data = get_puuids(summoner_id_batches['batch5'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 2 puuids/puuid_file_batch5\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_puuids, fp)\n",
    "\n",
    "#with open(\"summoner data/summoner_data_file_batch5\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bd05456-76f5-4511-af2d-bfd7e9dbf1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summoner_puuids, summoner_data = get_puuids(summoner_id_batches['batch6'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 2 puuids/puuid_file_batch6\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_puuids, fp)\n",
    "\n",
    "#with open(\"summoner data/summoner_data_file_batch6\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d60c144-e586-49db-954d-1be1753b508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summoner_puuids, summoner_data = get_puuids(summoner_id_batches['batch7'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 2 puuids/puuid_file_batch7\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_puuids, fp)\n",
    "\n",
    "#with open(\"summoner data/summoner_data_file_batch7\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(summoner_data, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9692b388-04b6-4582-8ba5-d193bdf45013",
   "metadata": {},
   "source": [
    "The puuid_file_batchX files are lists saved as pickle files. Each element of the list is a puuid. To unpickle, we use\n",
    "```\n",
    "with open(str(\"Step 2 puuids/puuid_file_batch0\"), \"rb\") as fp:   # Unpickling\n",
    "    summoner_puuids = pickle.load(fp) \n",
    "```\n",
    "\n",
    "\n",
    "The summoner_data_file_batchX files are dictionaries saved as pickle files. To unpickle them, we use\n",
    "```  \n",
    "with open(str(\"summoner data/summoner_data_file_batch0\"), \"rb\") as fp:   # Unpickling\n",
    "    summoner_data = pickle.load(fp) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2b05a-cc64-4e11-b2d1-0c87b5cc7005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09c46f-cff6-47e2-9881-ead4ff581263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c13a6f2-3635-42a6-a62c-4f5bb0982e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the puuid batch files as a dictionary\n",
    "puuid_batches = {}\n",
    "for i in range(0, 8):\n",
    "    with open(str(\"Step 2 puuids/puuid_file_batch\"+str(i)), \"rb\") as fp:   # Unpickling\n",
    "        puuid_batches[\"batch{0}\".format(i)] = pickle.load(fp)\n",
    "        \n",
    "# Load all the summoner_data batch files and combine them into a big dataframe\n",
    "summoner_data_batches = {}\n",
    "for i in range(0, 8):\n",
    "    with open(str(\"summoner data/summoner_data_file_batch\"+str(i)), \"rb\") as fp:   # Unpickling\n",
    "        summoner_data_batches[\"batch{0}\".format(i)] = pickle.load(fp)\n",
    "summoner_data = pd.concat(summoner_data_batches, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb5f52bb-ac74-40e5-8fc5-7038c65ce40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>accountId</th>\n",
       "      <th>puuid</th>\n",
       "      <th>name</th>\n",
       "      <th>profileIconId</th>\n",
       "      <th>revisionDate</th>\n",
       "      <th>summonerLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2TQCTFCJE1PI5WHMG2Qxjh_Vo_Ju8eQ2OarNradfNQ40ZHQ</td>\n",
       "      <td>E9F0b7xP56qjwXgmrPJWZdpie3Oe6NRCQGzvyePU9nayTA</td>\n",
       "      <td>HTUDJux_oQMU6ghOg1LS8TvaQnzDHZdMTLArzr7iEzcBAi...</td>\n",
       "      <td>Atesh</td>\n",
       "      <td>506</td>\n",
       "      <td>1662566903000</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YNRElnuhhS-iWtIVh0zlD_yIYSFK4bHnuGjjz-BEZrU3onA</td>\n",
       "      <td>FFRvjFILjiYVKsIaTwzQCn7NSsG50qD6RGnE1WGpG83V5Q</td>\n",
       "      <td>Bsa_8nMih4YPYLiJCoL09PnFG_RlBcMX2iPYdcehw3_rGh...</td>\n",
       "      <td>Guzoll</td>\n",
       "      <td>682</td>\n",
       "      <td>1666451932000</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SxDNYSfSqa_smQo1lIL0MpEppXHWiTBP1jyWIDTCEHAGK5...</td>\n",
       "      <td>KR0caZgtxgM8_Jsi0tq2vPMdroFcFGe1GJtrPpmMDGTYpp...</td>\n",
       "      <td>OVGe8En9cUxBp5JHf9_rSeksKG1ZCIIITokVXtGqZZns4L...</td>\n",
       "      <td>Fatsou</td>\n",
       "      <td>1298</td>\n",
       "      <td>1666218411000</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88aTHNaiQyG2gqLkuWwWTp-_aY7Q5oIbKDr4MK9te5Mcqpk</td>\n",
       "      <td>TkmbW74370Y8fwdafrqQf6lxK8fAtURb-jqg8EGkP0AxvAs</td>\n",
       "      <td>tAZdTPY_CkIosKcLBFiOWA_1YsTsDp5yQJYpOlERJR4CvP...</td>\n",
       "      <td>Szefciębson 2115</td>\n",
       "      <td>5413</td>\n",
       "      <td>1666480443122</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vp89cmGE32oYZcPJHayg8ijk4u96mShP0PumrMjtOmzhUNY</td>\n",
       "      <td>150FjKZZGdt1G5RO5wnaCzkEG0R_UeLow1HI1o5sIQeXBg</td>\n",
       "      <td>u3QcsJ56LtPuebqyXFK3nKqyrpBTPxQmUTSxWDGDEoaNBm...</td>\n",
       "      <td>marimitsous7</td>\n",
       "      <td>7</td>\n",
       "      <td>1652646921000</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0    2TQCTFCJE1PI5WHMG2Qxjh_Vo_Ju8eQ2OarNradfNQ40ZHQ   \n",
       "1    YNRElnuhhS-iWtIVh0zlD_yIYSFK4bHnuGjjz-BEZrU3onA   \n",
       "2  SxDNYSfSqa_smQo1lIL0MpEppXHWiTBP1jyWIDTCEHAGK5...   \n",
       "3    88aTHNaiQyG2gqLkuWwWTp-_aY7Q5oIbKDr4MK9te5Mcqpk   \n",
       "4    vp89cmGE32oYZcPJHayg8ijk4u96mShP0PumrMjtOmzhUNY   \n",
       "\n",
       "                                           accountId  \\\n",
       "0     E9F0b7xP56qjwXgmrPJWZdpie3Oe6NRCQGzvyePU9nayTA   \n",
       "1     FFRvjFILjiYVKsIaTwzQCn7NSsG50qD6RGnE1WGpG83V5Q   \n",
       "2  KR0caZgtxgM8_Jsi0tq2vPMdroFcFGe1GJtrPpmMDGTYpp...   \n",
       "3    TkmbW74370Y8fwdafrqQf6lxK8fAtURb-jqg8EGkP0AxvAs   \n",
       "4     150FjKZZGdt1G5RO5wnaCzkEG0R_UeLow1HI1o5sIQeXBg   \n",
       "\n",
       "                                               puuid              name  \\\n",
       "0  HTUDJux_oQMU6ghOg1LS8TvaQnzDHZdMTLArzr7iEzcBAi...             Atesh   \n",
       "1  Bsa_8nMih4YPYLiJCoL09PnFG_RlBcMX2iPYdcehw3_rGh...            Guzoll   \n",
       "2  OVGe8En9cUxBp5JHf9_rSeksKG1ZCIIITokVXtGqZZns4L...            Fatsou   \n",
       "3  tAZdTPY_CkIosKcLBFiOWA_1YsTsDp5yQJYpOlERJR4CvP...  Szefciębson 2115   \n",
       "4  u3QcsJ56LtPuebqyXFK3nKqyrpBTPxQmUTSxWDGDEoaNBm...      marimitsous7   \n",
       "\n",
       "   profileIconId   revisionDate  summonerLevel  \n",
       "0            506  1662566903000             92  \n",
       "1            682  1666451932000            365  \n",
       "2           1298  1666218411000            293  \n",
       "3           5413  1666480443122            489  \n",
       "4              7  1652646921000            172  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of the summoner information is contained in the dataframe summoner_data\n",
    "summoner_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39258bf3-74b0-49ec-8e60-e7bd4297aa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['batch0', 'batch1', 'batch2', 'batch3', 'batch4', 'batch5', 'batch6', 'batch7'])\n"
     ]
    }
   ],
   "source": [
    "# The puuids are now stored in a dictionary puuid_batches. The keys are\n",
    "print(puuid_batches.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb8eef52-c1c6-4155-9ccd-81b60c4529ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HTUDJux_oQMU6ghOg1LS8TvaQnzDHZdMTLArzr7iEzcBAiUdKyknzRuQhi06lgGkazYhUkLggSbpnw', 'Bsa_8nMih4YPYLiJCoL09PnFG_RlBcMX2iPYdcehw3_rGhkXt2P0P7TAxP3SGFtIE1HQ_feo9ZD-OA', 'OVGe8En9cUxBp5JHf9_rSeksKG1ZCIIITokVXtGqZZns4L2BmF3vfnSU-AUK1HvlMsZjh5V8p1ewsg', 'tAZdTPY_CkIosKcLBFiOWA_1YsTsDp5yQJYpOlERJR4CvPCZPdBznLXXBeVnrua7G4qLAVrtu3NWhg', 'u3QcsJ56LtPuebqyXFK3nKqyrpBTPxQmUTSxWDGDEoaNBma-l5XtBi4ek6_H9lAobEWqjmndK9OyVQ', 'bGPVaqe_Qz3rdcdlIm0RLMziqtrnw9Kq1heLT5OehAdTKicj65-f3c9XYW7CwLOOByk-Y1yk7lSiUw', 'Vy-EqEEU6ztNQL17IhUzhzf52ua9crMm5va9GCYrrPJJKtfIfGzyyEiF8z7B_2WeqvtwusveOfU46A', '0Jz41qAiK1a0ZD5TR9pajNlo9CJmGIG6vCtqwq64f5o0ne3YUuUEfODkRwFCNXp1REnL-2je_Un7pw', 'bPe2HKorRPMuBsUQIjPu2EDCPWIKq7XXAdLOkAv8g7eeuG6GSxyK-D3Zo_d_1PNdpM1sEG1I4k7Plg', '0kndBNuhuKcvp6N8tHCdHRlQobXkt0wBm1UUXFwzamfYeolwRgy4rMTQr3UOmggfo4HpTfI4q87J6Q']\n"
     ]
    }
   ],
   "source": [
    "# The first 10 elements of the first batch are\n",
    "print(puuid_batches[\"batch0\"][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491956c1-97cd-4849-84b8-cf4c636e5bfe",
   "metadata": {},
   "source": [
    "# Getting the Match IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acbc49aa-6354-4931-b168-f7ba135b8bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a list of puuids, we can query their match histories. We will also have to do this in batches. \n",
    "# Since we will be doing one query per puuid, it makes sense to use the batches we already have.\n",
    "\n",
    "#match_ids = get_match_ids(puuid_batches['batch0'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 3 match ids/match_id_file_batch0\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_ids, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e0f9a1a-9111-4a8e-86c2-e6759d53a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Approximately 3 hours\n",
    "\n",
    "# Now that we have a list of puuids, we can query their match histories. We will also have to do this in batches. \n",
    "# Since we will be doing one query per puuid, it makes sense to use the batches we already have.\n",
    "\n",
    "#match_ids = get_match_ids(puuid_batches['batch1'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 3 match ids/match_id_file_batch1\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_ids, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1aebbe6e-6863-4afb-a441-c760a72c29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Approximately 3 hours\n",
    "\n",
    "# Now that we have a list of puuids, we can query their match histories. We will also have to do this in batches. \n",
    "# Since we will be doing one query per puuid, it makes sense to use the batches we already have.\n",
    "\n",
    "#match_ids = get_match_ids(puuid_batches['batch2'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 3 match ids/match_id_file_batch2\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_ids, fp)\n",
    "    \n",
    "##################################################################################\n",
    "# Approximately 3 hours\n",
    "\n",
    "# Now that we have a list of puuids, we can query their match histories. We will also have to do this in batches. \n",
    "# Since we will be doing one query per puuid, it makes sense to use the batches we already have.\n",
    "\n",
    "#match_ids = get_match_ids(puuid_batches['batch3'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 3 match ids/match_id_file_batch3\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_ids, fp)\n",
    "    \n",
    "##################################################################################\n",
    "# Approximately 3 hours\n",
    "\n",
    "# Now that we have a list of puuids, we can query their match histories. We will also have to do this in batches. \n",
    "# Since we will be doing one query per puuid, it makes sense to use the batches we already have.\n",
    "\n",
    "#match_ids = get_match_ids(puuid_batches['batch4'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 3 match ids/match_id_file_batch4\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_ids, fp)\n",
    "    \n",
    "##################################################################################\n",
    "# Approximately 3 hours\n",
    "\n",
    "# Now that we have a list of puuids, we can query their match histories. We will also have to do this in batches. \n",
    "# Since we will be doing one query per puuid, it makes sense to use the batches we already have.\n",
    "\n",
    "#match_ids = get_match_ids(puuid_batches['batch5'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 3 match ids/match_id_file_batch5\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_ids, fp)\n",
    "    \n",
    "##################################################################################\n",
    "# Approximately 3 hours\n",
    "\n",
    "# Now that we have a list of puuids, we can query their match histories. We will also have to do this in batches. \n",
    "# Since we will be doing one query per puuid, it makes sense to use the batches we already have.\n",
    "\n",
    "#match_ids = get_match_ids(puuid_batches['batch6'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 3 match ids/match_id_file_batch6\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_ids, fp)\n",
    "    \n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b488c5a4-c86f-4502-bbe2-6da3c5efe0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximately 3 hours\n",
    "\n",
    "# Now that we have a list of puuids, we can query their match histories. We will also have to do this in batches. \n",
    "# Since we will be doing one query per puuid, it makes sense to use the batches we already have.\n",
    "\n",
    "#match_ids = get_match_ids(puuid_batches['batch7'])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 3 match ids/match_id_file_batch7\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_ids, fp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5ca08-4261-4dbd-bb42-88c4f3f13260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dd755a3-5ebd-4051-9b44-9ea27dc2067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the match_id batch files as a dictionary, making sure we only take unique values\n",
    "\n",
    "match_id_batches = {}\n",
    "for i in range(0, 8):\n",
    "    with open(str(\"Step 3 match ids/match_id_file_batch\"+str(i)), \"rb\") as fp:   # Unpickling\n",
    "        match_id_batches[\"batch{0}\".format(i)] = pickle.load(fp)\n",
    "        match_id_batches['batch{0}'.format(i)] = unique(match_id_batches['batch{0}'.format(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1d8b973-eac4-439b-8a82-12fb3886177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['batch0', 'batch1', 'batch2', 'batch3', 'batch4', 'batch5', 'batch6', 'batch7'])\n"
     ]
    }
   ],
   "source": [
    "# The match ids are now stored in a dictionary match_id_batches. The keys are\n",
    "print(match_id_batches.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70d753cc-62a2-4037-ac60-63495235ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EUN1_2949965728', 'EUN1_3198243338', 'EUN1_3231154689', 'EUN1_3205390161', 'EUN1_3196810490', 'EUN1_3206651913', 'EUN1_3164880211', 'EUN1_3228276362', 'EUN1_2873470913', 'EUN1_3207530104']\n"
     ]
    }
   ],
   "source": [
    "# The first ten elements of match_id_batches['batch0'] are:\n",
    "print(match_id_batches['batch0'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58c76234-754f-468c-81eb-db5b76417b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of match ids is 38.653157 million\n"
     ]
    }
   ],
   "source": [
    "# How many match ids do we have?\n",
    "match_id_count = 0\n",
    "for i in range(0,8):\n",
    "    match_id_count += len(match_id_batches['batch{0}'.format(i)])\n",
    "print(f'The number of match ids is {match_id_count/1000000} million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4178ca2f-29fa-4e73-a911-8768cc2765b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of matches for which I can obtain match data is about 345600.0 per day\n"
     ]
    }
   ],
   "source": [
    "# Let us suppose that I want to get match data over a period of 1 day. How much match data can I get? The rate limit I have is 8/2s.\n",
    "print(f'The number of matches for which I can obtain match data is about {60*60*24*(8/2)} per day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d202f41b-7cc3-4f47-9fab-a9ef0464f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means that I can get a million matches if I collect over three days. That's enough to start with. It is about a fifth of one batch.\n",
    "# This also means that it would take about 120 days to get all the match data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cac80e-436c-4927-a784-37c320de060c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0787b1e-18d1-4b4e-b552-1f03dadbef96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d783b5-78ac-49ad-a616-ddd4945b784c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6cedc91-b304-4287-a72e-8a83ea068698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the match IDs, but now we need the match data. Unfortunately, this is going to take a LONG time to get due to rate limiting, so we will be doing it in mini batches.\n",
    "# We will begin by splitting each match_id_batches into 100 mini batches.\n",
    "\n",
    "match_id_minibatches = {}\n",
    "for i in range(0,8):\n",
    "    match_id_minibatches['batch{0}'.format(i)] = list(chunks(match_id_batches['batch{0}'.format(i)], 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb3c7db-e740-4a6d-8252-6ac8100dfa14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec655d4-25cc-45ff-9214-b2fafff4c369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e864c9-606b-47f5-a8ce-632c151ada5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14064c-cce4-464b-aba8-ce9fc25c9dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2073d840-ec7b-425f-90ba-e51247c87155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, we now have a big list of match IDs split up into batches and minibatches. \n",
    "# Each minibatch should take about 3.5 hours to run. Let's test on one.\n",
    "\n",
    "#match_data = get_match_data(match_id_minibatches['batch0'][0])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 4 match data/batch0/minibatch0\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "759667e9-97b1-4e32-ac9d-c860e4c3f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, we now have a big list of match IDs split up into batches and minibatches. \n",
    "# Each minibatch should take about 3.5 hours to run.\n",
    "\n",
    "#match_data = get_match_data(match_id_minibatches['batch0'][1])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 4 match data/batch0/minibatch1\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f645f48d-f091-49ba-b1b0-3b29257adbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, we now have a big list of match IDs split up into batches and minibatches. \n",
    "# Each minibatch should take about 3.5 hours to run.\n",
    "\n",
    "#match_data = get_match_data(match_id_minibatches['batch0'][2])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 4 match data/batch0/minibatch2\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_data, fp)\n",
    "    \n",
    "#match_data = get_match_data(match_id_minibatches['batch0'][3])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 4 match data/batch0/minibatch3\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "764c360e-d9e8-462c-a747-925e5641d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, we now have a big list of match IDs split up into batches and minibatches. \n",
    "# Each minibatch should take about 3.5 hours to run.\n",
    "\n",
    "#match_data = get_match_data(match_id_minibatches['batch0'][4])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 4 match data/batch0/minibatch4\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1c5d63a-c56c-4331-b6dd-88271d628bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#match_data = get_match_data(match_id_minibatches['batch0'][5])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 4 match data/batch0/minibatch5\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9073c6e7-3c3f-4fd3-9b6a-e5a2f94ab4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#match_data = get_match_data(match_id_minibatches['batch0'][6])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 4 match data/batch0/minibatch6\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d474e82-d44b-4435-bdf3-e819f5ea9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#match_data = get_match_data(match_id_minibatches['batch0'][7])\n",
    "\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"Step 4 match data/batch0/minibatch7\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(match_data, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a75bf4-9085-486b-8cfc-8d3dff035512",
   "metadata": {},
   "source": [
    "## That's probably enough for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "530deae6-b835-4dc0-b02e-3781ef045803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234ba5093d3947d6bfc810e52f318ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dd17e4c9c34436925f1f07f561f246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb916e1bcee145c99b5e70138ca2e76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca528dd56419463ba625875949dd5f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c150263b610443f08b6a071578c8630f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48284 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fed3f234a4411f8e8d731609c42351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddefe4e91b34b269a89c2530fc5c91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d20ae3757c040878b086b22bbd7e731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd808790e1b8461cb691475ee17d8953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This loading is quite slow since the games have a lot of information and there are a lot of games.\n",
    "\n",
    "ranked_matches = []\n",
    "\n",
    "for i in tqdm(range(0, 8)):\n",
    "    with open(str(\"Step 4 match data/batch0/minibatch\"+str(i)), \"rb\") as fp:   # Unpickling\n",
    "        match_data = pickle.load(fp)\n",
    "    \n",
    "    batch_ranked_matches = []\n",
    "    for match in tqdm(range(len(match_data))):\n",
    "        for j in range(10):\n",
    "            if (match_data[match]['info']['gameDuration'] >= 900) and (match_data[match]['info']['queueId'] == 420):\n",
    "                row_dict = {k: match_data[match]['info']['participants'][j][k] for k in ('win', 'championName', 'teamId', 'summonerName')}\n",
    "                row_dict['team'] = 'Blue' if row_dict['teamId']==100 else 'Red'\n",
    "                row_dict['matchId'] = match_data[match]['metadata']['matchId']\n",
    "                row_dict['gameMode'] = match_data[match]['info']['queueId']\n",
    "                batch_ranked_matches.append(row_dict)\n",
    "\n",
    "        \n",
    "    ranked_matches = ranked_matches+ batch_ranked_matches\n",
    "\n",
    "rankeddf = pd.DataFrame(ranked_matches)\n",
    "rankeddf = rankeddf.drop(columns=['teamId'])\n",
    "rankeddf = rankeddf.set_index(['matchId', 'team'])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08121a9f-2cc3-4127-be03-8a2d5233cced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1710440"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ranked_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec1c44-556b-4b8d-9b93-d793a44d84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have approximately 100000 mateches to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff015f0-9c5d-40af-aebc-3de96098c0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df1c652-7a37-4e7c-8221-cb36ba1cac58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd0633-6ea8-48c2-9c68-80e2461878f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006fdfb-f831-4ce2-8a40-f7d92558639e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23192f7-3dfd-4577-98e4-34a5614de16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e1233-6989-4fde-b687-556505b35762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8ebcf-bcf0-4b41-9791-dd6f9711aead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02ad28-5697-481d-9e9e-00f85b247d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0480d4d-0d49-4ea0-9c74-9e5548d3fe00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23343e3c-2b21-4e8f-adeb-9c4e6157ba7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a24e4-129b-4938-a2e3-7bd34214487b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67490087-08a6-415c-a9d0-53d37e1fc60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ee076-8508-4173-a5ef-b94232a9c6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4c5bc-f9dc-4aec-a1ef-85261e595297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec1960-4a2c-45d9-bd4f-117bdaea3ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6962ba-dfa8-4c65-9990-3567fb5ed4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db203d42-016e-4e5d-8be6-b17641649fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>win</th>\n",
       "      <th>championName</th>\n",
       "      <th>summonerName</th>\n",
       "      <th>gameMode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchId</th>\n",
       "      <th>team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">EUN1_3205133592</th>\n",
       "      <th>Blue</th>\n",
       "      <td>False</td>\n",
       "      <td>TahmKench</td>\n",
       "      <td>mariogrzyb321</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>False</td>\n",
       "      <td>Elise</td>\n",
       "      <td>xBakuu</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>False</td>\n",
       "      <td>Azir</td>\n",
       "      <td>Vecrone</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>False</td>\n",
       "      <td>Jhin</td>\n",
       "      <td>UNfriendlyEwok</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>False</td>\n",
       "      <td>Yuumi</td>\n",
       "      <td>metrosexual</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>True</td>\n",
       "      <td>Garen</td>\n",
       "      <td>DEMACI4</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>True</td>\n",
       "      <td>Kayn</td>\n",
       "      <td>zombieldtv</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>True</td>\n",
       "      <td>Cassiopeia</td>\n",
       "      <td>whimsical 11 19</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>True</td>\n",
       "      <td>Varus</td>\n",
       "      <td>ΞΞ ZielU ΞΞ</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>True</td>\n",
       "      <td>Xerath</td>\n",
       "      <td>savo2kk</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">EUN1_3128873118</th>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>DrMundo</td>\n",
       "      <td>Báttya</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>Warwick</td>\n",
       "      <td>Prince Of Lillie</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>Graves</td>\n",
       "      <td>janosthevitez</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>MissFortune</td>\n",
       "      <td>sliz5</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>Nautilus</td>\n",
       "      <td>Sparrov7</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>Garen</td>\n",
       "      <td>beowulfe001</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>XinZhao</td>\n",
       "      <td>kubajess85</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>Malzahar</td>\n",
       "      <td>Dimmon</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>Ezreal</td>\n",
       "      <td>papardeΙas</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>Renata</td>\n",
       "      <td>Cherryyy</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">EUN1_3189901232</th>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>Yasuo</td>\n",
       "      <td>Onehundred</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>Qiyana</td>\n",
       "      <td>bania778</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>Akali</td>\n",
       "      <td>CryFockMeSatan</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>Sivir</td>\n",
       "      <td>LeeJohnnySinsUwU</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>True</td>\n",
       "      <td>Ashe</td>\n",
       "      <td>White Yuri</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>Mordekaiser</td>\n",
       "      <td>Jew Vanisher</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>Vi</td>\n",
       "      <td>rolerpro</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>Yone</td>\n",
       "      <td>Dr Holocaust</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>Ezreal</td>\n",
       "      <td>Jirka The Great</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>False</td>\n",
       "      <td>Xerath</td>\n",
       "      <td>ksmaster420</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        win championName      summonerName  gameMode\n",
       "matchId         team                                                \n",
       "EUN1_3205133592 Blue  False    TahmKench     mariogrzyb321       420\n",
       "                Blue  False        Elise            xBakuu       420\n",
       "                Blue  False         Azir           Vecrone       420\n",
       "                Blue  False         Jhin    UNfriendlyEwok       420\n",
       "                Blue  False        Yuumi       metrosexual       420\n",
       "                Red    True        Garen           DEMACI4       420\n",
       "                Red    True         Kayn        zombieldtv       420\n",
       "                Red    True   Cassiopeia   whimsical 11 19       420\n",
       "                Red    True        Varus       ΞΞ ZielU ΞΞ       420\n",
       "                Red    True       Xerath           savo2kk       420\n",
       "EUN1_3128873118 Blue   True      DrMundo            Báttya       420\n",
       "                Blue   True      Warwick  Prince Of Lillie       420\n",
       "                Blue   True       Graves     janosthevitez       420\n",
       "                Blue   True  MissFortune             sliz5       420\n",
       "                Blue   True     Nautilus          Sparrov7       420\n",
       "                Red   False        Garen       beowulfe001       420\n",
       "                Red   False      XinZhao        kubajess85       420\n",
       "                Red   False     Malzahar            Dimmon       420\n",
       "                Red   False       Ezreal        papardeΙas       420\n",
       "                Red   False       Renata          Cherryyy       420\n",
       "EUN1_3189901232 Blue   True        Yasuo        Onehundred       420\n",
       "                Blue   True       Qiyana          bania778       420\n",
       "                Blue   True        Akali    CryFockMeSatan       420\n",
       "                Blue   True        Sivir  LeeJohnnySinsUwU       420\n",
       "                Blue   True         Ashe        White Yuri       420\n",
       "                Red   False  Mordekaiser      Jew Vanisher       420\n",
       "                Red   False           Vi          rolerpro       420\n",
       "                Red   False         Yone      Dr Holocaust       420\n",
       "                Red   False       Ezreal   Jirka The Great       420\n",
       "                Red   False       Xerath       ksmaster420       420"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankeddf.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "657fc373-7a5a-405d-adfd-8c965eda1125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1710440 entries, ('EUN1_3205133592', 'Blue') to ('EUN1_3191594151', 'Red')\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   win           bool  \n",
      " 1   championName  object\n",
      " 2   summonerName  object\n",
      " 3   gameMode      int64 \n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 54.2+ MB\n"
     ]
    }
   ],
   "source": [
    "rankeddf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e4ff6de-f65a-4136-bf50-a19e834f113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like we have a nice pool of ~21000 ranked games to begin with. Not bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "521af4d0-872f-4301-a4e0-b6b3b9a9efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save this as a csv which we will import in the next notebook.\n",
    "rankeddf.to_csv('ranked_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a216d6-0a03-4d83-8a1b-994b86c1a966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57468db-f5d4-4d63-8b78-4122e5b049fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a05a2-2942-4dfc-93fb-95602da2d89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee584d0-5670-4f2c-9ec3-369f15c899db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a4b10-14e5-48ad-8cc1-e2841696dc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ed559-0c91-4552-86cf-11b4bf3c6ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579283be-7476-436d-b8aa-9e025f68cc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ea676-ca7b-4918-b054-67a996be8993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72758881-669b-4189-b50f-bb2166ae4f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
