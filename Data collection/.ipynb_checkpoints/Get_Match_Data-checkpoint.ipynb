{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7000f112-5022-4cb4-8f87-9a3e87897d1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting match data from the RIOT games API\n",
    "This notebook goes through the process of aggregating match data from the RIOT games API. Due to rate limiting and the convoluted method of obtaining match data, the process can take quite a while. Where possible, I have saved the intermediate results so that long steps do not need to be repeated. \n",
    "\n",
    "## Here is the workflow for obtaining the data:\n",
    "\n",
    "1. ### Obtain summoner IDs by looking up the summoner data from the first page of each tier and division \n",
    "(No saving required, since there are only about 20 API calls to make)\n",
    "\n",
    "2. ### Use those summoner IDs to obtain the corresponding PUUIDs\n",
    "(save puuids in a pickle file 'PUUIDs' )\n",
    "\n",
    "3. ### Use the PUUIDs to query the match history of those summoners, obtaining a list of match IDs\n",
    "(save match IDs in a pickle file 'match_IDs' )\n",
    "\n",
    "4. ### Use the match IDs to get the match data\n",
    "(save match data in a pickle file 'match_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6bf66e-3062-4b60-8b48-481a6625e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Mark Bugden\n",
    "August 2022\n",
    "\n",
    "Part of a ML project in predicting win rates for League of Legends games based on team composition.\n",
    "Current update available on GitHub: https://github.com/Mark-Bugden\n",
    "\"\"\"\n",
    "\n",
    "# Import anything necessary\n",
    "import requests\n",
    "import pandas as pd\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "import pickle\n",
    "\n",
    "\n",
    "# This gives us a progress bar for longer computations. \n",
    "from tqdm.notebook import tqdm\n",
    "# To use it, just wrap any iterable with tqdm(iterable).\n",
    "# Eg: \n",
    "# for i in tqdm(range(100)):\n",
    "#     ....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We need to pick a region. \n",
    "region_list = ['BR1', 'EUN1', 'EUW1', 'JP1', 'KR', 'LA1', 'LA2', 'NA1', 'OC1', 'RU', 'TR1']\n",
    "region = 'EUN1'\n",
    "\n",
    "\n",
    "# Here are the tiers and divisions\n",
    "tier_list = ['DIAMOND', 'PLATINUM', 'GOLD', 'SILVER', 'BRONZE', 'IRON']\n",
    "division_list = ['I', 'II', 'III', 'IV']\n",
    "\n",
    "\n",
    "\n",
    "# Load the data for the champions\n",
    "champion_url = 'http://ddragon.leagueoflegends.com/cdn/12.14.1/data/en_US/champion.json'\n",
    "r = requests.get(champion_url)\n",
    "json_data = r.json()\n",
    "champion_data = json_data['data']\n",
    "\n",
    "#champions = list(champion_data.keys())\n",
    "#champion_data['Zyra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66d108-b745-4581-a53f-74154d1f65f6",
   "metadata": {},
   "source": [
    "### Note: \n",
    "The API rates are meant to be 20/1s and 100/120s, but I have found that I get errors when I set the ratelimit to exactly that. I have found that I don't get any errors when I set it at half the rate, which works for now, but doubles the time required to get the data. I should try it again att slightly over half the rate, to see if I get an error. If I do, then I am probably accidentally accessing the API twice per call instead of once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b07449-eca4-4c37-a66e-6d388592ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful functions\n",
    "\n",
    "\n",
    "def flatten(l):\n",
    "    ''' Flattens a list\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        l:list\n",
    "            A list to be flattened\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            The flattened list\n",
    "    \n",
    "    '''\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def unique(l):\n",
    "    ''' Returns the unique elements of a list\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        l:list\n",
    "            A list you want the unique elements of\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            The unique elements of the list (unordered)\n",
    "    \n",
    "    '''\n",
    "    return list(set(l))\n",
    "\n",
    "# We will need an API key to access the Riot games API. I have one of these, but I don't want it to be publically available on my GitHub, so I am storing it locally in a text file. \n",
    "\n",
    "def getAPI_key():\n",
    "    ''' Accesses my locally stored API key so that I don't have to include it publically on GitHub\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        string:\n",
    "            My API key for RIOT games\n",
    "\n",
    "    '''\n",
    "    f = open(\"api_key.txt\", \"r\")\n",
    "    return f.read()\n",
    "\n",
    "\n",
    "\n",
    "# Our API calls are rate limited to 100 every 2 minutes, or 20 every second. So we will use the ratelimit package to limit how many times we call the API. \n",
    "# If the rate limit is reached, the program will sleep until it can try again. We will set the rate to 5 calls per 7s. This will be slower for short queries, but won't give us errors long ones.\n",
    "# Note that it should be 5/6s, but for some reason that gave me Error:429. Trying 7s just to be a bit safer.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(5, 7)\n",
    "def callAPI(url):\n",
    "    ''' Send and retrieve API requests, rate limited to the RIOT games API rate limit. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        url: string\n",
    "            The URL of the request you are making. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list of dictionaries encoding the data accessed. \n",
    "    '''\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        raise Exception('API response: {}'.format(r.status_code))\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "# If I am getting a 401 error, I probably just need to refresh my API key from the developer website\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_summoner_ids(page=1):\n",
    "    '''\n",
    "    Aggregates a list of summoner ids from the first page of all the low-ranking tiers and divisions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        page: int\n",
    "            Which page is queried for the summoner info\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list of summoner ids\n",
    "    \n",
    "    '''\n",
    "    summoners = []\n",
    "\n",
    "    # For all leagues from Iron to Diamond, and for all tiers from I to IV, send a request to get the first page of the summoners for that league and tier.\n",
    "    for tier in tqdm(tier_list):\n",
    "        for division in division_list:\n",
    "\n",
    "            url = 'https://' + region + '.api.riotgames.com/lol/league/v4/entries/RANKED_SOLO_5x5/' + tier + '/' + division + '?page=' + str(page) + '&api_key='\n",
    "\n",
    "            # Here json_data is a list. Each item in the list corresponds to one summoner, and is a dict whose key/value pairs contain information about that summoner.\n",
    "            json_data = callAPI(url + getAPI_key())\n",
    "            \n",
    "\n",
    "            for item in json_data:\n",
    "                summoners.append(item)\n",
    "\n",
    "    summoners_df = pd.DataFrame(summoners)\n",
    "\n",
    "    return summoners_df['summonerId'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_puuids(ids):\n",
    "    ''' Takes a list of summoner ids and queries the RIOT API for their puuids\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        ids: list\n",
    "            A list of summoner ids\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list of the corresponding puuids\n",
    "    '''\n",
    "    \n",
    "    summoner_info = []\n",
    "\n",
    "    for summoner in tqdm(ids):\n",
    "        url = 'https://' + region + '.api.riotgames.com/lol/summoner/v4/summoners/' + summoner + '?api_key='\n",
    "        json_data = callAPI(url + getAPI_key())\n",
    "        summoner_info.append(json_data)\n",
    "    df_summ = pd.DataFrame(summoner_info)\n",
    "    \n",
    "    return df_summ['puuid'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_match_ids(puuids, n = 10):\n",
    "    ''' Takes a list of puuids and returns the match IDs for the previous n matches. Any duplicate match IDs are removed. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        puuids: list\n",
    "            A list of puuids to query\n",
    "        n: int \n",
    "            The number of matches to get per puuid\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list of match ids\n",
    "    '''\n",
    "    \n",
    "    match_id = []\n",
    "    \n",
    "    for puuid in tqdm(puuids):\n",
    "        url = 'https://europe.api.riotgames.com/lol/match/v5/matches/by-puuid/' + puuid + '/ids?start=0&count=100&api_key='\n",
    "        json_data = callAPI(url + getAPI_key())\n",
    "        match_id.append(json_data)\n",
    "    \n",
    "    return list(set(flatten(match_id)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_match_data(batch):\n",
    "    ''' Accesses the match data for a given batch of match ids and returns the data as a list\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        batch: list\n",
    "            A list of match ids \n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "        list\n",
    "            A list containing the match data for each of the match ids in batch\n",
    "            \n",
    "    '''\n",
    "    data_list = []\n",
    "    \n",
    "    for match in tqdm(batch):\n",
    "        url = 'https://europe.api.riotgames.com/lol/match/v5/matches/'+ match + '?api_key='\n",
    "        json_data = callAPI(url + getAPI_key())\n",
    "        data_list.append(json_data)\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1fc47-0fd2-42b0-ad45-937f885894c4",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5fdb02-e286-4142-9f57-777b3e183273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the summoner ids is as easy as calling the get_summoner_list function \n",
    "#summoner_ids = get_summoner_ids()\n",
    "\n",
    "# We already have these, so we can just load them.\n",
    "with open(\"Step 1 summoner ids/summoner_id_file\", \"rb\") as fp:   # Unpickling\n",
    "    summoner_ids = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44623473-1820-4307-ad85-fb1d6231431b",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ba3cf1-be3c-492e-8914-8dfe431b9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the summoners IDs, we can call get_puuids to get the associated puuids. Remember this step takes a long time, since we need one query per ID.\n",
    "#summoner_puuids = get_puuids(summoner_ids[0:20])\n",
    "# Save this to pickle file since it took a long time to get\n",
    "#with open(\"puuid_file\", \"wb\") as fp:   #Pickling\n",
    "    #pickle.dump(summoner_puuids, fp)\n",
    "    \n",
    "# We already have these, so we can just load them.\n",
    "summoner_puuids = {}\n",
    "for i in range(8):\n",
    "    with open(f\"Step 2 puuids/puuid_file_batch{i}\", \"rb\") as fp:   # Unpickling\n",
    "        summoner_puuids[i] = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3324e69-7a14-4246-82bb-d707ccc32fd5",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682c5507-8838-4d5f-bfd8-78dbf1a4dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a list of puuids, we can query their match histories\n",
    "# This takes a long time, so we will do it in batches.\n",
    "\n",
    "#match_ids = get_match_ids(summoner_puuids)\n",
    "\n",
    "# We already have the match ids, so we can just load them\n",
    "match_ids_batches = {}\n",
    "for i in range(8):\n",
    "    with open(f\"Step 3 match ids/match_id_file_batch{i}\", \"rb\") as fp:   # Unpickling\n",
    "        match_ids_batches[i] = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a72138-5669-41a1-89d6-7f7c4f3db8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ids = []\n",
    "for i in range(8):\n",
    "    match_ids += match_ids_batches[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0256e31-5edb-422b-8d86-bd5ecc7b25f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38653157"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have approximately 3.8 million match ids\n",
    "len(match_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da21ef94-8719-4df5-9ecb-2ff9d519ef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28558609"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many of these are unique?\n",
    "match_ids = unique(match_ids)\n",
    "len(match_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a15055-3d5f-4236-97b3-3d3348c85b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximately 2.8 million unique matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e660fd-d721-496d-b281-31ad5a051b22",
   "metadata": {},
   "source": [
    "# Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65dfd9ea-ae54-4533-a43e-c2d7faf0fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the match IDs, but now we need the match data. Unfortunately, this is going to take a LONG time to get due to rate limiting, so we will be doing it in batches.\n",
    "#match_id_firstbatch = match_ids[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2539bbc-6009-4f0e-8ab4-b99c43b55d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2367e7e908466280e03e4e888924ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Great, we now have a big list of match IDs. We can now access the match data for each of the match IDs in the first batch. \n",
    "#match_data = get_match_data(match_id_firstbatch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8384da33-c7ab-499b-9bb0-94811505099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load in one of the minibatch data files.\n",
    "# In later iterations of this, we will do all the minibatches here.\n",
    "match_data_batches = {}\n",
    "for i in tqdm(range(8)):\n",
    "    with open(\"Step 4 match data/batch0/minibatch{i}\", \"rb\") as fp:   # Unpickling\n",
    "        match_data_batches[i] = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f69c58-de97-49b6-916a-525366066daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = []\n",
    "match_data += match_data_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83747641-0671-4aa4-8827-374d2474b31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8775c-fa23-4820-93a4-c5edf2142492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ddd0633-6ea8-48c2-9c68-80e2461878f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48287"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match_data is a big list where each element contains the data for a single match. We will construct a DataFrame from all this data.\n",
    "len(match_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006fdfb-f831-4ce2-8a40-f7d92558639e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c23192f7-3dfd-4577-98e4-34a5614de16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['metadata', 'info'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each element is a match, and each match is a dict, whose keys are metadata and info. For the first match, we have\n",
    "match_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de7e1233-6989-4fde-b687-556505b35762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metadata keys are:  dict_keys(['dataVersion', 'matchId', 'participants']) \n",
      "\n",
      "The info keys are:  dict_keys(['gameCreation', 'gameDuration', 'gameEndTimestamp', 'gameId', 'gameMode', 'gameName', 'gameStartTimestamp', 'gameType', 'gameVersion', 'mapId', 'participants', 'platformId', 'queueId', 'teams', 'tournamentCode'])\n"
     ]
    }
   ],
   "source": [
    "# To be honest, we don't really care about the metadata, except for maybe the matchId\n",
    "# The info is much more relevant for us. It is also a dict, with a lot of different entries. We'll be interested in the participants for now.\n",
    "\n",
    "print(\"The metadata keys are: \", match_data[0]['metadata'].keys(), \"\\n\")\n",
    "print(\"The info keys are: \", match_data[0]['info'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8ebcf-bcf0-4b41-9791-dd6f9711aead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f02ad28-5697-481d-9e9e-00f85b247d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game mode:  CLASSIC\n",
      "Duration (mins):  30.916666666666668\n"
     ]
    }
   ],
   "source": [
    "# Here we can see what game mode the first match was, and how long it lasted.  \n",
    "# We will need to subset our data to include only ranked games, and games which didn't end in a forfeit (say, under 15mins).\n",
    "\n",
    "print('Game mode: ', match_data[0]['info']['gameMode'])\n",
    "print(\"Duration (mins): \", match_data[0]['info']['gameDuration']/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23343e3c-2b21-4e8f-adeb-9c4e6157ba7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['assists', 'baronKills', 'basicPings', 'bountyLevel', 'challenges', 'champExperience', 'champLevel', 'championId', 'championName', 'championTransform', 'consumablesPurchased', 'damageDealtToBuildings', 'damageDealtToObjectives', 'damageDealtToTurrets', 'damageSelfMitigated', 'deaths', 'detectorWardsPlaced', 'doubleKills', 'dragonKills', 'eligibleForProgression', 'firstBloodAssist', 'firstBloodKill', 'firstTowerAssist', 'firstTowerKill', 'gameEndedInEarlySurrender', 'gameEndedInSurrender', 'goldEarned', 'goldSpent', 'individualPosition', 'inhibitorKills', 'inhibitorTakedowns', 'inhibitorsLost', 'item0', 'item1', 'item2', 'item3', 'item4', 'item5', 'item6', 'itemsPurchased', 'killingSprees', 'kills', 'lane', 'largestCriticalStrike', 'largestKillingSpree', 'largestMultiKill', 'longestTimeSpentLiving', 'magicDamageDealt', 'magicDamageDealtToChampions', 'magicDamageTaken', 'neutralMinionsKilled', 'nexusKills', 'nexusLost', 'nexusTakedowns', 'objectivesStolen', 'objectivesStolenAssists', 'participantId', 'pentaKills', 'perks', 'physicalDamageDealt', 'physicalDamageDealtToChampions', 'physicalDamageTaken', 'profileIcon', 'puuid', 'quadraKills', 'riotIdName', 'riotIdTagline', 'role', 'sightWardsBoughtInGame', 'spell1Casts', 'spell2Casts', 'spell3Casts', 'spell4Casts', 'summoner1Casts', 'summoner1Id', 'summoner2Casts', 'summoner2Id', 'summonerId', 'summonerLevel', 'summonerName', 'teamEarlySurrendered', 'teamId', 'teamPosition', 'timeCCingOthers', 'timePlayed', 'totalDamageDealt', 'totalDamageDealtToChampions', 'totalDamageShieldedOnTeammates', 'totalDamageTaken', 'totalHeal', 'totalHealsOnTeammates', 'totalMinionsKilled', 'totalTimeCCDealt', 'totalTimeSpentDead', 'totalUnitsHealed', 'tripleKills', 'trueDamageDealt', 'trueDamageDealtToChampions', 'trueDamageTaken', 'turretKills', 'turretTakedowns', 'turretsLost', 'unrealKills', 'visionScore', 'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced', 'win'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Participants is a list with 10 entries (for normal game modes). Each entry is a dict containing information about each summoner. For example, the first summoner has the following info:\n",
    "match_data[0]['info']['participants'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac7a24e4-129b-4938-a2e3-7bd34214487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TahmKench\n",
      "Elise\n",
      "Azir\n",
      "Jhin\n",
      "Yuumi\n",
      "Garen\n",
      "Kayn\n",
      "Cassiopeia\n",
      "Varus\n",
      "Xerath\n"
     ]
    }
   ],
   "source": [
    "# We can get a list of the champions in the first game:\n",
    "for summoner in match_data[0]['info']['participants']:\n",
    "    print(summoner['championName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67490087-08a6-415c-a9d0-53d37e1fc60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca2ee076-8508-4173-a5ef-b94232a9c6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 TahmKench False\n",
      "100 Elise False\n",
      "100 Azir False\n",
      "100 Jhin False\n",
      "100 Yuumi False\n",
      "200 Garen True\n",
      "200 Kayn True\n",
      "200 Cassiopeia True\n",
      "200 Varus True\n",
      "200 Xerath True\n"
     ]
    }
   ],
   "source": [
    "# We can see what team they are on, whether they won or lost, etc\n",
    "# Note: team 100 is blue team, team 200 is red team\n",
    "\n",
    "for summoner in match_data[0]['info']['participants']:\n",
    "    print(summoner['teamId'], summoner['championName'], summoner['win'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4c5bc-f9dc-4aec-a1ef-85261e595297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bec1960-4a2c-45d9-bd4f-117bdaea3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are interested in ranked games that last at least 15 minutes, we will create a new DataFrame with only such games, and only keep information relevant to our project.\n",
    "# All of the match data will always still be available as the match_data list\n",
    "# Note that this loop doesn't involve API calls and is therefore not rate limited - it should run relatively quickly. \n",
    "\n",
    "ranked_matches = []\n",
    "for match in range(len(match_data)):\n",
    "    for i in range(10):\n",
    "        if (match_data[match]['info']['gameDuration'] >= 900) and (match_data[match]['info']['queueId'] == 420):\n",
    "            row_dict = {k: match_data[match]['info']['participants'][i][k] for k in ('win', 'championName', 'teamId', 'summonerName')}\n",
    "            row_dict['team'] = 'Blue' if row_dict['teamId']==100 else 'Red'\n",
    "            row_dict['matchId'] = match_data[match]['metadata']['matchId']\n",
    "            row_dict['gameMode'] = match_data[match]['info']['queueId']\n",
    "            ranked_matches.append(row_dict)\n",
    "\n",
    "        \n",
    "rankeddf = pd.DataFrame(ranked_matches)\n",
    "rankeddf = rankeddf.drop(columns=['teamId'])\n",
    "rankeddf = rankeddf.set_index(['matchId', 'team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab5261-5267-457c-aa4d-9a69e5d37c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b6962ba-dfa8-4c65-9990-3567fb5ed4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save this as a csv which we will import in the next notebook.\n",
    "rankeddf.to_csv('ranked_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db203d42-016e-4e5d-8be6-b17641649fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fc373-7a5a-405d-adfd-8c965eda1125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ff6de-f65a-4136-bf50-a19e834f113c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521af4d0-872f-4301-a4e0-b6b3b9a9efa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a216d6-0a03-4d83-8a1b-994b86c1a966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
